--evaluation_strategy epoch
--per_device_train_batch_size 8
--per_device_eval_batch_size 16
--learning_rate 1e-5
--weight_decay 0.0
--optim adamw_hf
--adam_beta1 0.9
--adam_beta2 0.999
--adam_epsilon 1e-8
--max_grad_norm 1.0
--num_train_epochs 40
--lr_scheduler_type linear
--warmup_steps 100
--log_level info
--logging_strategy steps
--logging_steps 100
--save_strategy no
--metric_for_best_model loss
